{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "/home/nollyd/anaconda3/envs/minerl/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import minerl  # NOTE: we need gym>=0.13.1,<0.20\n",
    "import gym\n",
    "from train import get_agent, get_dynamics_environment, FMC, get_data_handler\n",
    "from fgz.training.fgz_trainer import FGZTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # fix memory leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minerl_env = gym.make('MineRLBasaltFindCave-v0')\n",
    "agent = get_agent()\n",
    "# dynamics_env = get_dynamics_environment(minerl_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamics_env.batched_action_space_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_initial_state = torch.ones(4096, dtype=float)\n",
    "# dynamics_env.set_all_states(dummy_initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T(Player658-63ba09594583-20220708-123749)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_handler = get_data_handler(agent)\n",
    "str(data_handler.loaders[0].trajectories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39msample_single_trajectory()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(window))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame, state_embedding, action \u001b[38;5;129;01min\u001b[39;00m window:\n",
      "File \u001b[0;32m~/Code/basalt_2022_competition_nollied/fgz/data_utils/data_handler.py:60\u001b[0m, in \u001b[0;36mContiguousTrajectoryWindow.__next__\u001b[0;34m(self, populating)\u001b[0m\n\u001b[1;32m     58\u001b[0m frame, action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trajectory_iterator\u001b[39m.\u001b[39m\u001b[39m__next__\u001b[39m()\n\u001b[1;32m     59\u001b[0m \u001b[39mprint\u001b[39m(frame\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 60\u001b[0m state_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mget_embedding({\u001b[39m\"\u001b[39;49m\u001b[39mpov\u001b[39;49m\u001b[39m\"\u001b[39;49m: frame})  \u001b[39m# TODO: this doesn't take into consideration batching!\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow\u001b[39m.\u001b[39mappend((frame, state_embedding, action))\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_per_window:\n",
      "File \u001b[0;32m~/Code/minerl_2022/vpt/vpt/agent.py:212\u001b[0m, in \u001b[0;36mMineRLAgent.get_embedding\u001b[0;34m(self, minerl_obs)\u001b[0m\n\u001b[1;32m    208\u001b[0m agent_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_env_obs_to_agent(minerl_obs)\n\u001b[1;32m    209\u001b[0m \u001b[39m# The \"first\" argument could be used to reset tell episode\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# boundaries, but we are only using this for predicting (for now),\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m# so we do not hassle with it yet.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mforward(agent_input, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dummy_first, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_state, return_embedding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Code/minerl_2022/vpt/vpt/lib/policy.py:267\u001b[0m, in \u001b[0;36mMinecraftAgentPolicy.forward\u001b[0;34m(self, obs, first, state_in, return_embedding, last_action)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m (pi_h, v_h), state_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(obs, state_in, context\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mfirst\u001b[39;49m\u001b[39m\"\u001b[39;49m: first}, last_action\u001b[39m=\u001b[39;49mlast_action)\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m return_embedding:\n\u001b[1;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m pi_h\n",
      "File \u001b[0;32m~/anaconda3/envs/minerl/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/minerl_2022/vpt/vpt/lib/policy.py:197\u001b[0m, in \u001b[0;36mMinecraftPolicy.forward\u001b[0;34m(self, ob, state_in, context, last_action)\u001b[0m\n\u001b[1;32m    194\u001b[0m first \u001b[39m=\u001b[39m context[\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    196\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_preprocess(ob[\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 197\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_process(x)\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiff_obs_process:\n\u001b[1;32m    200\u001b[0m     processed_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiff_obs_process(ob[\u001b[39m\"\u001b[39m\u001b[39mdiff_goal\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/minerl/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/minerl_2022/vpt/vpt/lib/policy.py:80\u001b[0m, in \u001b[0;36mImgObsProcess.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(img))\n",
      "File \u001b[0;32m~/anaconda3/envs/minerl/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/minerl_2022/vpt/vpt/lib/impala_cnn.py:188\u001b[0m, in \u001b[0;36mImpalaCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 188\u001b[0m     b, t \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m]\n\u001b[1;32m    189\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mreshape(b \u001b[39m*\u001b[39m t, \u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:])\n\u001b[1;32m    190\u001b[0m     x \u001b[39m=\u001b[39m misc\u001b[39m.\u001b[39mtranspose(x, \u001b[39m\"\u001b[39m\u001b[39mbhwc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbchw\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "t = data_handler.sample_single_trajectory()\n",
    "for window in t:\n",
    "    print(len(window))\n",
    "    for frame, state_embedding, action in window:\n",
    "        print(state_embedding.shape)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmc = FMC(dynamics_env, freeze_best=True)\n",
    "# trainer = FGZTrainer(minerl_env, agent, fmc, unroll_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmc.simulate(4, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmc.tree.render() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state, action in fmc.tree.best_path:\n",
    "#     print(state.reward, state.observation.var(), action)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train_trajectory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('minerl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32f88b1943610b2b4002ab57fb2488113fc1952d4ac8f2580706d8ed13983308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
